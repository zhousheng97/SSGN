includes:
- common/defaults/configs/datasets/vqa/microsoft_textvqa.yml
# Use soft copy
dataset_attributes:
  microsoft_textvqa:
    image_features:
      train:
      - data/feat_resx/train,data/ocr_feat_resx/textvqa_conf/train_images,micro_tvqa_edge_feat_full/train  #micro_textvqa_adaptive_edge_top5/train
      - data/feat_resx/stvqa/train,data/ocr_feat_resx/stvqa_conf,micro_stvqa_edge_feat_full #micro_stvqa_adaptive_edge_top5
      val:
      - data/feat_resx/train,data/ocr_feat_resx/textvqa_conf/train_images,micro_tvqa_edge_feat_full/train #micro_textvqa_adaptive_edge_top5/train
      test:
      - data/feat_resx/test,data/ocr_feat_resx/textvqa_conf/test_images,micro_tvqa_edge_feat_full/test #micro_textvqa_adaptive_edge_top5/test
    imdb_files:
      train:
      # - data/imdb/micro_textvqa/imdb_microsoft_textvqa_train.npy
      # - data/imdb/micro_stvqa/imdb_microsoft_stvqa_train.npy
      - data/imdb_add_phrase/micro_textvqa/imdb_add_phrase_microsoft_textvqa_train.npy
      - data/imdb_add_phrase/micro_stvqa/imdb_add_phrase_microsoft_stvqa_train.npy
      val:
      # - data/imdb/micro_textvqa/imdb_microsoft_textvqa_val.npy
      # - data/imdb_add_phrase/micro_textvqa/imdb_add_phrase_microsoft_textvqa_val.npy
      - data/imdb_add_phrase/micro_textvqa/imdb_add_phrase_microsoft_textvqa_val.npy
      test:
      # - data/imdb/micro_textvqa/imdb_microsoft_textvqa_test.npy
      - data/imdb_add_phrase/micro_textvqa/imdb_add_phrase_microsoft_textvqa_test.npy
    processors:
      text_processor:
        type: bert_tokenizer  # roberta_tokenizer
        params:
          max_length: 20
      answer_processor:
        type: m4c_answer
        params:
          vocab_file: data/m4c_vocabs/textvqa/fixed_answer_vocab_textvqa_5k.txt
          preprocessor:
            type: simple_word
            params: {}
          context_preprocessor:
            type: simple_word
            params: {}
          max_length: 50
          max_copy_steps: 12
          num_answers: 10
      copy_processor:
        type: copy
        params:
          max_length: 100  # 100
      phoc_processor:
        type: phoc
        params:
          max_length: 50
model_attributes:
  ssgn:
    lr_scale_frcn: 0.1
    lr_scale_text_bert: 0.1
    lr_scale_mmt: 1.0  # no scaling
    text_bert_init_from_bert_base: true
    text_bert:
      num_hidden_layers: 3
      hidden_size: 768
      max_length: 10
    obj:
      mmt_in_dim: 2048
      dropout_prob: 0.1
    ocr:
      mmt_in_dim: 3002    # 300 (FastText) + 604 (PHOC) + 2048 (Faster R-CNN) + 512(RecogCNN) 
      dropout_prob: 0.1
    PAM:
      hidden_size: 768
      num_hidden_layers: 2
    MRG:
      hidden_size: 768
    Three_Graph:
      hidden_size: 768
    mmt:
      hidden_size: 768
      num_hidden_layers: 4
    classifier:
      type: linear
      ocr_max_num: 50
      ocr_ptr_net:
        hidden_size: 768
        query_key_size: 768
      params: {}
    model_data_dir: ../data/microsoft_textvqa
    metrics:
    - type: textvqa_accuracy
    losses:
    - type: multi
      params:
      - type: m4c_decoding_bce_with_mask
        weight: 1.0
        params: {}
      - type: anls_reward
        weight: 1.0
        params: {}
optimizer_attributes:
  params:
    eps: 1.0e-08
    lr: 1e-4
    weight_decay: 0
  type: Adam
training_parameters:
    clip_norm_mode: all
    clip_gradients: true
    max_grad_l2_norm: 0.25
    lr_scheduler: true
    lr_steps:
    - 11000
    - 21000
    lr_ratio: 0.1
    use_warmup: true
    warmup_factor: 0.2
    warmup_iterations: 1000
    max_iterations: 25000
    batch_size: 128
    num_workers: 8
    task_size_proportional_sampling: true
    monitored_metric: microsoft_textvqa/textvqa_accuracy
    metric_minimize: false